import { useState, useRef, useEffect } from "react";
import { getAIChat } from "../api";

function Chat() {
  const [isListening, setIsListening] = useState(false);
  const [userSpeech, setUserSpeech] = useState("");
  const [chatHistory, setChatHistory] = useState([]);
  const [volume, setVolume] = useState(0); // ìŒì„± ë³¼ë¥¨ ìƒíƒœ

  const recognitionRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const sourceRef = useRef(null);
  const rafIdRef = useRef(null);

  // ë³¼ë¥¨ ì¸¡ì • í•¨ìˆ˜
  const analyzeVolume = () => {
    if (!analyserRef.current) return;

    const bufferLength = analyserRef.current.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    analyserRef.current.getByteFrequencyData(dataArray);

    let sum = 0;
    for (let i = 0; i < bufferLength; i++) {
      sum += dataArray[i];
    }
    const average = sum / bufferLength;

    setVolume(average);

    rafIdRef.current = requestAnimationFrame(analyzeVolume);
  };

  const handleStartListening = async () => {
    if (isListening) return; // ì´ë¯¸ ì¼œì ¸ ìˆìœ¼ë©´ ë¬´ì‹œ

    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    const recognition = new SpeechRecognition();
    recognitionRef.current = recognition;

    recognition.lang = "ko-KR";
    recognition.interimResults = true;
    recognition.continuous = true; // ì¤‘ë‹¨ ì—†ì´ ì¸ì‹ ìœ ì§€

    recognition.onstart = () => {
      setIsListening(true);
      setUserSpeech("");
    };

    recognition.onresult = (event) => {
      const transcript = Array.from(event.results)
        .map((result) => result[0].transcript)
        .join("");
      setUserSpeech(transcript);
    };

    recognition.onerror = (event) => {
      console.error("SpeechRecognition error", event.error);
    };

    recognition.onend = () => {
      setIsListening(false);
      stopAudioAnalysis();
    };

    recognition.start();

    // Web Audio API ì…‹ì—…
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioContextRef.current = new AudioContext();
      analyserRef.current = audioContextRef.current.createAnalyser();
      sourceRef.current =
        audioContextRef.current.createMediaStreamSource(stream);

      sourceRef.current.connect(analyserRef.current);
      analyserRef.current.fftSize = 256;

      analyzeVolume();
    } catch (err) {
      console.error("Audio setup error:", err);
    }
  };

  const stopAudioAnalysis = () => {
    if (rafIdRef.current) {
      cancelAnimationFrame(rafIdRef.current);
    }
    if (analyserRef.current) {
      analyserRef.current.disconnect();
      analyserRef.current = null;
    }
    if (sourceRef.current) {
      sourceRef.current.disconnect();
      sourceRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
  };

  const handleSubmit = async () => {
    if (!userSpeech.trim()) return;

    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
    stopAudioAnalysis();

    try {
      const aiResponse = await getAIChat(userSpeech);
      setChatHistory((prev) => [...prev, { user: userSpeech, ai: aiResponse }]);
      setUserSpeech("");
    } catch (err) {
      console.error("AI ì‘ë‹µ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨");
    }
  };

  // íŒŒí˜•(ë³¼ë¥¨) ë†’ì´ì— ë”°ë¼ ë§‰ëŒ€ ë†’ì´ ì¡°ì ˆìš© ìŠ¤íƒ€ì¼
  const bars = 10;
  const barElements = [];
  for (let i = 0; i < bars; i++) {
    // ë³¼ë¥¨ì„ 0~1 ë²”ìœ„ë¡œ normalize (ì ì ˆíˆ ì¡°ì •)
    const height = Math.min(50, (volume / 256) * 100 + Math.random() * 10);
    barElements.push(
      <div
        key={i}
        style={{
          width: 5,
          height,
          margin: "0 2px",
          backgroundColor: "#4caf50",
          borderRadius: 2,
          transition: "height 0.1s ease",
          display: "inline-block",
        }}
      ></div>
    );
  }

  return (
    <div>
      <h1>AI ì±„íŒ…</h1>

      <button onClick={handleStartListening} disabled={isListening}>
        ğŸ¤ ìŒì„± ì¸ì‹ ì‹œì‘
      </button>

      {isListening && (
        <div
          style={{
            margin: "10px 0",
            height: 60,
            display: "flex",
            alignItems: "flex-end",
          }}
        >
          {barElements}
        </div>
      )}

      <p>
        <strong>ì‚¬ìš©ì ì…ë ¥:</strong> {userSpeech}
      </p>

      <button
        onClick={handleSubmit}
        disabled={!isListening && !userSpeech.trim()}
      >
        ë‹µë³€ì™„ë£Œ
      </button>

      <div>
        <h2>ëŒ€í™” ê¸°ë¡</h2>
        <ul>
          {chatHistory.map((entry, index) => (
            <li key={index} style={{ marginBottom: 10 }}>
              <p>
                <strong>ğŸ‘¤ ë‚˜:</strong> {entry.user}
              </p>
              <p>
                <strong>ğŸ¤– AI:</strong> {entry.ai}
              </p>
            </li>
          ))}
        </ul>
      </div>
    </div>
  );
}

export default Chat;
